---
title: "Run an R script as a background job"
description: |
  When working with R you may want to run a script that require quite a long time to complete. 
  As modern computers generally have more cores and ram than required this is not going to be a problem in terms of computer resources.
  Nevertheless, the script will take your R prompt busy preventing you from any other activity. 
  Function `rstudioapi::jobRunScript()` allows you avoid this problem. 

author:
  - name: Andrea Spano
    url: andreaspano.github.io
    affiliation: Quantide
    affiliation_url: www.quantide.com
date: "`r Sys.Date()`"
bibliography: 
  biblio.bib
output:
  distill::distill_article:
    self_contained: false
editor_options: 
  chunk_output_type: console
preview: logo.png
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##  Introduction 

When working with R you may want to run a script that require quite a long time to complete. 

As a basic non sense example consider:


```{r, eval = FALSE}
n <- 1200
y <- numeric(n)
for ( i in seq_len(n)){
  y[[i]] <- i 
  Sys.sleep(3)
}
sum(y)
```
<br>

This script, say `wait-for-me.R` when executed takes about one hour. 

If executed directly from the R console it will keep your R session busy for one hour preventing you to keep working on you current R session. 

In order to avoid this waste of time you can use three different approaches: 

1. R CMD BATCH 
2. RScript 
3. jobRunScript

## R CMD BATCH 

R CMD BATCH is a bash utility that allows you to run R in batch mode at the Unix terminal

The usual command is:

```{shell , eval = FALSE}
R CMD BATCH infile.R outfile.log
```
<br>

`R` executes the instructions from `infile.R` and writes the output, both stdout and stderr, to `outfile.log`

The above instruction silently implies two extra default parameters:

```{shell , eval = FALSE}
R CMD BATCH --restore --save infile.R outfile.log
```
<br>

 - `--save`: save the environment at the end of the computation into a file named `.RData`

 - `--restore`: restore any `.RData` file into the R environment prior starting the computation


I believe batch R scripts should be run by 

```{shell , eval = FALSE}
R CMD BATCH --no-restore --no-save infile.R outfile.log
```
<br>

When R terminates the execution of `infile.R` the working environment where the computation occurred is not saved. 
Therefore, if you want save any object, this should be done explicitly with instructions like `save()`,`saveRDS()` or `readr::write_rds()`.
You can always import the files generated from these functions into your working session by using instructions like `load()`, `readRDS()`. `readr::read_rds()`.

In the above case, the R script runs in almost complete self isolation. In order to achieve complete isolation you should write:

```{shell , eval = FALSE}
R CMD BATCH --no-restore --no-save --no-environ --no-site-file --no-init-file infile.R outfile.log
```
<br>

- `--no-environ`: do not use any environmental variables from teh user profile 
- `--no-site-file`: do to execute .Rprofile.site  prior running teh computation 
- `--no-init-file`: do to execute local .Rprofile  prior running teh computation 

Note that the long above command can be  shortened into:

```{shell , eval = FALSE}
R CMD BATCH --vanilla infile.R outfile.log
```
<br>

In case you want to run `R CMD BATCH` and see `R` output at the unx terminal rather than in a file, the following will do the trick:


```{shell , eval = FALSE}
mkfifo Rfifo
cat Rfifo &
R CMD BATCH --vanilla infile.R Rfifo
```
<br>






## jobRunScript [@rstudioapi]

Function `jobRunScript()` from package `rstudioapi` is a newer and interesting alternative.

`jobRunScript()` is an R function from package `rstudioapi` and not a bash utility. As a result, you can run it at you R prompt within RStudio. `jobRunScript()` will execute your script in background and immediately return your R session available to you. Clearly, as `jobRunScript()` is part of or package `rstudioapi` it will not work outside RStudio




```{r,  eval = FALSE}
require(rstudioapi)
jobRunScript(path = './wait-for-me.R', 
             name = 'wait for me',
             encoding = "unknown", 
             workingDir = NULL,
             importEnv = FALSE, 
             exportEnv = "R_GlobalEnv")
```
<br>

This command tells R to run your script and export the objects created within this environment  

As stated by the function help:

* __path__: The path to the R script to be run.

* __name__: A name for the background job. When NULL (the default), the filename of the script is used as the job name.

* __encoding__: The text encoding of the script, if known.

* __workingDir__: The working directory in which to run the job. When NULL (the default), the parent directory of the R script is used.

* __importEnv__: Whether to import the global environment into the job.

* __exportEnv__: The name of the environment in which to export the R objects created by the job. Use "" (the default) to skip export, "R_GlobalEnv"' to export to the global environment, or the name of an environment object to create an object with that name.

Therefore, if you want to run a job a collect the results back in your working environmentyou need to set:  `exportEnv = "R_GlobalEnv"`

In case you need to pass any object from your global environmemnt to teh script you may want to use importEnv = TRUE. Personally, I woulkd not reccomend this choice. A script would be better to be seft contained and not to depend from objects defined elsewhere. 





