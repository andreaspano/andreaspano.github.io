[
  {
    "path": "posts/2021-11-18-installing-r-from-source/",
    "title": "Installing R from source",
    "description": "Installing a specific version of R on Linux Ubuntu requires to compile it from source code",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2021-11-18",
    "categories": [],
    "contents": "\nIntro\nInstalling R from source is required whenever you need a specific version of R rather than latest release available as binary on either CRAN or Ubuntu repositories.\nInstall required dependencies\nEnable the required and optional repositories. You will need them to check R installation dependencies.\nAd the R pubblic key\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key '95C0FAF38DB3CCAD0C080A7BDC78B2DDEABC47B7'\nAdd the following lines in /etc/apt/source.list\ndeb http://cloud.r-project.org/bin/linux/debian bullseye-cran40/\ndeb-src  http://cloud.r-project.org/bin/linux/debian bullseye-cran40/\nNext update and, install the build dependencies for R:\nsudo apt update\nsudo apt-get build-dep r-base\nAfter checking dependencies you’d better comment those lines in source.list.\nSpecify R version\nexport R_VERSION=4.1.2\nDownload and extract R\ncurl -O https://cran.rstudio.com/src/base/R-4/R-${R_VERSION}.tar.gz\ntar -xzvf R-${R_VERSION}.tar.gz\ncd R-${R_VERSION}\nConfigure R\n./configure \\\n    --prefix=/opt/R/${R_VERSION} \\\n    --enable-memory-profiling \\\n    --enable-R-shlib \\\n    --with-blas \\\n    --with-lapack \\\n    --with-tcltk\nTcltk has been added as packages TSclust and TSdist wont compile\nBuild and install R\nmake\nsudo make install\nVerify R installation\n/opt/R/${R_VERSION}/bin/R --version\nCreate a symlink to R\nTo ensure that R is available on the default system PATH variable, create symbolic links to the version of R that you installed:\nsudo ln -fs /opt/R/${R_VERSION}/bin/R /usr/local/bin/R\nsudo ln -fs /opt/R/${R_VERSION}/bin/Rscript /usr/local/bin/Rscript\nThe f flag force symlink to recreate and therefore to update from previous R versions\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-18T11:29:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-18-reinstalling-all-r-pkgs/",
    "title": "Reinstalling all R pkgs",
    "description": "When installing a new version of R you may want to  reinstall al previously installed packages for the new R version. \nNew packages will be installed a new directory.",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2021-11-18",
    "categories": [],
    "contents": "\nAssuming that ol packages have been installed in\n~/R/x86_64-pc-linux-gnu-library/4.0/\nand that you want to install new packages in\n~/R/x86_64-pc-linux-gnu-library/4.1/\nDefine installation directories\nld_loc <- \"~/R/x86_64-pc-linux-gnu-library/4.0/\"\nnew_loc <- \"~/R/x86_64-pc-linux-gnu-library/4.1/\"\nIf new path does not exists, create it\nif ( !dir.exists(new_loc)) {dir.create(new_loc)}\nGrab all old installed packages\npkgs <- installed.packages(lib.loc = old_loc)[, \"Package\"]\nInstall new packages in the location\ninstall.packages(pkgs, \n                 lib = new_loc, \n                 ask = FALSE , \n                 repos =   'https://cran.wu.ac.at/',\n                 dependencies = TRUE, \n                 Ncpus = 8)\nNote that not all packages may install correctly but, the vast majority most of them will.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-18T13:25:28+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-03-environmental-variables-in-rocker/",
    "title": "Environmental variables in Rocker",
    "description": "How to use environmental variables to pass values to a R docker",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2021-10-03",
    "categories": [],
    "contents": "\nIntroduction\nThe idea of having R docker able to get external values when running is quite interesting.\nAs an example, suppose you have a docker that performs x+1 and that you want to pass x to the docker when running it.\nThe easiest way consist of forcing R to read x from an environmental variable, say X and then pass X to the docker with the --env option.\nDocker File\nSuppose you have a R docker build by the following dockerfile:\nFROM rocker/r-ver:4.0.5\n\nRUN mkdir /data\n \nRUN mkdir /app\nRUN chmod -R 755 /app\n\nWORKDIR /app\nADD main.R .\nCMD R -e  \"source('main.R')\"\n\nMain R script\nWhere the script main.R is:\nx <- Sys.getenv(\"X\")\ny <- x+1\nwrite(y, '/data/y.txt')\nRun\nAfter building the docker with:\ndocker build -t mydocker .\nYou can run it with\nsudo docker run --env X=99 --rm -v /data/:/data  mydocker\nYou should see the value of y, presumably 100, in the output file y.txt\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-03T23:04:14+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-27-interactive-plotly/",
    "title": "Interactive Plotly",
    "description": "The idea is about using package `plotly` for producing  interactive plots for a Shiny application.  \nOfficial documentation about `plotly` is superb. \nNevertheless, as this graphics grammar, within the `R` community is not as spread as `ggplot` is, few topics require a bit of extra research.",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2021-04-04",
    "categories": [],
    "contents": "\nIntro\nGiven\na data set with four columns: x, y , w, z\na plot x and y onto pl1\nplot w and z onto pl2\npl as a subplot of pl1 and pl2\nI would like to:\nbe able to select a set of adiacent points in pl1\nobserve the selected points marked with new color and larger size\nobserve the same effect on corresponding points on pl2\nI will be using the classic iris data for this example.\nStep 1:\nLoad the required packages\n\n\nrequire(plotly)\nrequire(dplyr)\n\n\n\nStep 2:\nAdd a unique id to data\n\n\ndata <- iris %>% mutate ( id = 1:n())\n\n\n\nStep 3:\nTransform data into a ShareData object\n\n\ndata <- data %>% highlight_key(~id) \n\n\n\nStep 4:\nBuild your plots as you would normally do\n\n\npl1 <- plot_ly(data, \n               x = ~ Sepal.Length, y = ~Sepal.Width, \n               type = 'scatter', mode = 'markers', \n               marker = list ( color = 'green')) %>% \n  layout(showlegend=F)\n               \npl2 <- plot_ly(data, \n               x = ~Petal.Length, y = ~Petal.Width, \n               type = 'scatter', mode = 'markers',\n               marker = list ( color = 'blue')) %>% \n  layout(showlegend=F)\n\n\n\nStep 5:\nBind your plots into a single subplot\n\n\npl <- subplot(pl1, pl2, nrows = 2)\n\n\n\nStep 6:\nLink the plots\n\n\npl <- pl %>% \n  highlight(on = \"plotly_select\", off = 'plotly_doubleclick', \n            opacityDim = .5, \n            selected = attrs_selected(marker = list ( size = 20, color = 'orange')))\n\n\n\nStep 7:\nDisplay results\n\n\npl\n\n\n\n{\"x\":{\"data\":[{\"x\":[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],\"y\":[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],\"mode\":\"markers\",\"marker\":{\"color\":\"green\",\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"type\":\"scatter\",\"key\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],\"set\":\"SharedData462bacb6\",\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"_isNestedKey\":false,\"frame\":null},{\"x\":[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],\"y\":[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],\"mode\":\"markers\",\"marker\":{\"color\":\"blue\",\"line\":{\"color\":\"rgba(255,127,14,1)\"}},\"type\":\"scatter\",\"key\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],\"set\":\"SharedData462bacb6\",\"error_y\":{\"color\":\"rgba(255,127,14,1)\"},\"error_x\":{\"color\":\"rgba(255,127,14,1)\"},\"line\":{\"color\":\"rgba(255,127,14,1)\"},\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"_isNestedKey\":false,\"frame\":null}],\"layout\":{\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"anchor\":\"y\"},\"xaxis2\":{\"domain\":[0,1],\"automargin\":true,\"anchor\":\"y2\"},\"yaxis2\":{\"domain\":[0,0.48],\"automargin\":true,\"anchor\":\"x2\"},\"yaxis\":{\"domain\":[0.52,1],\"automargin\":true,\"anchor\":\"x\"},\"annotations\":[],\"shapes\":[],\"images\":[],\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"showlegend\":false,\"dragmode\":\"select\",\"hovermode\":\"closest\"},\"attrs\":{\"1b3ae45753fda7\":{\"x\":{},\"y\":{},\"mode\":\"markers\",\"marker\":{\"color\":\"green\"},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\"},\"1b3ae42eceb093\":{\"x\":{},\"y\":{},\"mode\":\"markers\",\"marker\":{\"color\":\"blue\"},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter\"}},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"highlight\":{\"on\":\"plotly_selected\",\"off\":\"plotly_doubleclick\",\"persistent\":false,\"dynamic\":false,\"color\":null,\"selectize\":false,\"defaultValues\":null,\"opacityDim\":0.5,\"selected\":{\"marker\":{\"size\":20,\"color\":\"orange\"},\"opacity\":1},\"debounce\":0,\"ctGroups\":[\"SharedData462bacb6\"]},\"subplot\":true,\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-04T15:35:46+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-29-run-an-r-script-as-a-background-job/",
    "title": "Run an R script as a background job",
    "description": "When working with R you may want to run a script that require quite a long time to complete. \nAs modern computers generally have more cores and ram than required this is not going to be a problem in terms of computer resources.\nNevertheless, the script will take your R prompt busy preventing you from any other activity. \nFunction `rstudioapi::jobRunScript()` allows you avoid this problem.",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2021-03-27",
    "categories": [],
    "contents": "\n\nContents\nIntroduction\nR CMD BATCH\nRscript\njobRunScript (Kevin 2020)\n\nIntroduction\nWhen working with R you may want to run a script, say infile.R, that requires quite a long time to complete.\nIf you execute this script directly from the R console, it will keep your R session busy for long time preventing you from working on you current R session.\nNote that R is single thread, meaning that it takes resources from a single core, while modern computer have plenty of resources available, usually eight or more cores. Assuming that your script is not too eager in terms of RAM, you can easily send your script on anther core and keep working on your current R session.\nIn order to achive this goal you can use three different approaches:\nR CMD BATCH\nRScript\njobRunScript\nR CMD BATCH\nR CMD BATCH is a bash utility that allows you to run R in batch mode at the Unix terminal\nThe usual command is:\n\nR CMD BATCH infile.R outfile.log\n\n\nR executes the instructions from infile.R and writes the output, both stdout and stderr, to outfile.log\nThe above instruction silently implies two extra default parameters:\n\nR CMD BATCH --restore --save infile.R outfile.log\n\n\n--save: save the environment at the end of the computation into a file named .RData\n--restore: restore any .RData file into the R environment prior starting the computation\nI believe batch R scripts should be run by\n\nR CMD BATCH --no-restore --no-save infile.R outfile.log\n\n\nWith the above command, when R terminates the execution of infile.R the working environment where the computation occurred is not saved.\nTherefore, if you want save any object, this should be done explicitly with instructions like save(),saveRDS() or readr::write_rds().\nYou can always import the files generated from these functions into your working session by using instructions like load(), readRDS(). readr::read_rds().\nIn the above case, the R script runs in almost complete self isolation. In order to achieve complete isolation you should write:\n\nR CMD BATCH --no-restore --no-save --no-environ --no-site-file --no-init-file infile.R outfile.log\n\n\n--no-environ: do not use any environmental variables from the user profile\n--no-site-file: do to execute .Rprofile.site prior running the computation\n--no-init-file: do to execute local .Rprofile prior running the computation\nNote that the long above command can be shortened into:\n\nR CMD BATCH --vanilla infile.R outfile.log\n\n\nIn case you want to run R CMD BATCH and see R output at the Unix terminal rather than in a file, the following will do the trick:\n\nmkfifo Rfifo\ncat Rfifo &\nR CMD BATCH --vanilla infile.R Rfifo\n\n\nIn some situations you may want to pass arguments to the batch script. Quite often this happens when you want to run the same script against different data sources In this case, you do not want to write a version of your script for each data source but a single script that takes your data source as a parameter.\nSuppose a piece of code, saved in a file count.R, that simply count the number of rows in a file:\n\n\nargs <- commandArgs(trailingOnly = TRUE)\nfile <- args[[1]]\nlength(readLines(file))\n\n\n\nYou can invoke script count.R with:\n\nR CMD BATCH --vanilla '--args ~/tmp/count.R i.txt'  count.R count.log \n\nYou can read the output by editing count.log\nRscript\nRScript is an executable command that comes with R.\nIt takes as input any properly quoted R expression or script file. Output is usually redirected to stdout.\nAs a basic example with a single expression\n\nRscript  -e '1+1'\n\nOr with more than one expression separated bu semicolon\n\nRscript  -e '1+1; 2+2'\n\nTO BE CONTINUED\njobRunScript (Kevin 2020)\nFunction jobRunScript() from package rstudioapi is a newer and interesting alternative.\njobRunScript() is an R function from package rstudioapi and not a bash utility. As a result, you can run it at you R prompt within RStudio. jobRunScript() will execute your script in background and immediately return your R session available to you. Clearly, as jobRunScript() is part of or package rstudioapi it will not work outside RStudio\n\n\nrequire(rstudioapi)\njobRunScript(path = 'infile.R', \n             name = 'my long script',\n             encoding = \"unknown\", \n             workingDir = NULL,\n             importEnv = FALSE, \n             exportEnv = \"R_GlobalEnv\")\n\n\n\n\nThis command tells R to run your script and export the objects created within this environment\nAs stated by the function help:\npath: The path to the R script to be run.\nname: A name for the background job. When NULL (the default), the filename of the script is used as the job name.\nencoding: The text encoding of the script, if known.\nworkingDir: The working directory in which to run the job. When NULL (the default), the parent directory of the R script is used.\nimportEnv: Whether to import the global environment into the job.\nexportEnv: The name of the environment in which to export the R objects created by the job. Use \"\" (the default) to skip export, “R_GlobalEnv”’ to export to the global environment, or the name of an environment object to create an object with that name.\nTherefore, if you want to run a job a collect the results back in your working environmentyou need to set: exportEnv = \"R_GlobalEnv\"\nIn case you need to pass any object from your global environmemnt to teh script you may want to use importEnv = TRUE. Personally, I woulkd not reccomend this choice. A script would be better to be seft contained and not to depend from objects defined elsewhere.\n\n\n\nKevin, Ushey. 2020. “Rstudio Api V0.9.0.” https://www.rdocumentation.org/packages/rstudioapi/versions/0.9.0.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-03-27T22:48:12+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-10-06-data-analysis-with-spraklyr/",
    "title": "Data Analysis with Sparklyr",
    "description": "Sparklyr is an open-source package that provides an interface between R and Apache Spark. \nSparklyr provide an interface to use Spark as the backend for dplyr along with acess to Spark’s distributed machine learning algorithms\nThis article is about using sparkly within an R session",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2020-10-10",
    "categories": [],
    "contents": "\nPkgs\nLoad required packages\n\n\nrequire(sparklyr)\nrequire(dplyr)\nrequire(readr)\nrequire(ggplot2)\n\nSet up\nSpark environment setup\n\n\n# global spark memory\nSys.setenv(\"SPARK_MEM\" = \"32g\")\n# Initialize configuration with defaults\nconfig <- spark_config()\n# Memory\nconfig[\"sparklyr.shell.driver-memory\"] <- \"32g\"\n# Cores\nconfig[\"sparklyr.connect.cores.local\"] <- 6\n\nConnect\nCreate local Spark context\n\n\nsc <- spark_connect(master = \"local\", version = \"3.0\", config = config)\n\ncsv files\nLoad csv files\n\n\nsystem.time({\nd_all <- spark_read_csv(sc , \n               name = 'd_all',\n               path = \"file:///data/airline/csv\",\n               header = T)\n})\n\n   user  system elapsed \n  0.386   0.021 349.361 \n\nSave as parquet\n\n\nsystem('rm -rf /data/airline/prq/')\nsystem.time({\n  spark_write_parquet(d_all, path = '/data/airline/prq/')\n})\n\n   user  system elapsed \n  0.100   0.009 166.966 \n\nDisconnect from spark context and reload\n\n\nspark_disconnect(sc)\nsc <- spark_connect(master = \"local\", version = \"3.0\", config = config)\n\nload parquet\n\n\nsystem.time({\n  d_all <- spark_read_parquet(sc , \n                          name = 'd_all',\n                          path = \"file:///data/airline/prq/\", \n                          header = T)\n  \n})\n\n   user  system elapsed \n  0.296   0.009 255.523 \n\nCheck data size\n\n\nsystem.time({\nn <- d_all %>% \n  summarise(n = n()) %>% \n  collect()\n\nprint(n) \n})\n\n# A tibble: 1 x 1\n          n\n      <dbl>\n1 123536460\n\n   user  system elapsed \n  0.106   0.000   0.665 \n\nprepare model data\nSelect variables of interests only\n\n\nsystem.time({\nd_model <- d_all %>%\n  mutate(ArrDelay = as.numeric(ArrDelay) ,\n         DepDelay = as.numeric(DepDelay) ,\n         Distance = as.numeric(Distance)) %>% \n  filter(!is.na(ArrDelay) & !is.na(DepDelay) & !is.na(Distance)) %>%\n  filter(DepDelay > -10 & DepDelay < 240) %>%\n  filter(ArrDelay > -60 & ArrDelay < 360) %>% \n  mutate(Gain = DepDelay - ArrDelay) %>%\n  select(Year, Month, ArrDelay, DepDelay, Distance, UniqueCarrier, Gain)\n})\n\n   user  system elapsed \n  0.018   0.000   0.018 \n\nCheck newdata dimension\n\n\nsystem.time({\nn <- d_model %>% \n  summarise(n = n()) %>% \n  collect()\nprint(n)\n})\n\n# A tibble: 1 x 1\n          n\n      <dbl>\n1 118734210\n\n   user  system elapsed \n  0.219   0.007  51.889 \n\nimport carriers data\n\n\nd_carrier <- spark_read_csv(sc , \n                          name = 'd_carrier',\n                          path = \"file:///data/airline/csv/carriers.csv\", \n                          header = T)\n\njoin airlines data with carriers data\n\n\nsystem.time({\nd_model <- d_model %>% \n  left_join(d_carrier, by = c(\"UniqueCarrier\" = \"Code\"))\n})\n\n   user  system elapsed \n  0.002   0.000   0.002 \n\nsplit data into training and out of sample test\n\n\nsystem.time({\n  d_model_2008 <- d_model %>% filter(Year == 2008)\n  d_model <- d_model %>% filter(Year <= 2007)\n})\n\n   user  system elapsed \n  0.001   0.000   0.001 \n\ncheck dimensions\n\n\nsystem.time({\nn <- d_model %>%  summarise(n = n())\nn2008 <- d_model_2008 %>%  summarise(n = n())\nprint(n)\nprint(n2008)\n})\n\n# Source: spark<?> [?? x 1]\n          n\n      <dbl>\n1 112181520\n# Source: spark<?> [?? x 1]\n        n\n    <dbl>\n1 6552690\n\n   user  system elapsed \n  1.103   0.004  87.384 \n\npartition the data into training and validation sets\n\n\nsystem.time({\nmodel_partition <- d_model %>% \n  sdf_random_split(d_trn = 0.8, d_tst = 0.2, seed = 5555)\n})\n\n   user  system elapsed \n  0.129   0.000   0.274 \n\nModelling\nFit a linear model\n\n\nsystem.time({\n  fm <-  ml_linear_regression(model_partition$d_trn, \n                            formula = Gain ~ Distance + DepDelay + UniqueCarrier)\n})\n\n   user  system elapsed \n  0.831   0.017 452.703 \n\nShow summary\n\n\nsystem.time({  \n  summary(fm) \n})\n\nDeviance Residuals (approximate):\n     Min       1Q   Median       3Q      Max \n-265.919   -5.051    1.269    6.894   65.380 \n\nCoefficients:\n         (Intercept)             Distance             DepDelay \n         0.531353277          0.001558469         -0.026397469 \n    UniqueCarrier_DL     UniqueCarrier_WN     UniqueCarrier_AA \n        -1.743534978          2.303278665         -0.799773763 \n    UniqueCarrier_US     UniqueCarrier_UA     UniqueCarrier_NW \n        -0.382524595         -0.665547422         -0.937718509 \n    UniqueCarrier_CO     UniqueCarrier_TW     UniqueCarrier_HP \n        -1.120225017         -0.746713781         -0.990743725 \n    UniqueCarrier_MQ     UniqueCarrier_AS     UniqueCarrier_OO \n        -0.237436154         -1.821968437          0.520332347 \n    UniqueCarrier_XE     UniqueCarrier_EV     UniqueCarrier_OH \n        -2.088189831          2.174881667          0.974134885 \n    UniqueCarrier_FL     UniqueCarrier_EA     UniqueCarrier_PI \n        -0.348562712         -0.064621000         -2.407988812 \n    UniqueCarrier_DH     UniqueCarrier_B6     UniqueCarrier_YV \n         1.957873863         -0.131815707          1.284944000 \nUniqueCarrier_PA (1)     UniqueCarrier_9E     UniqueCarrier_F9 \n        -1.421766146         -0.100683233         -1.101344304 \n    UniqueCarrier_HA     UniqueCarrier_TZ     UniqueCarrier_AQ \n        -0.866472290         -2.662288749         -0.648046560 \n    UniqueCarrier_PS \n        -1.213938612 \n\nR-Squared: 0.01378\nRoot Mean Squared Error: 12.73\n\n   user  system elapsed \n  0.155   0.017 196.604 \n\nCalculate average gains by predicted decile\n\n\nsystem.time({\nmodel_deciles <- lapply(model_partition, \n                        function(x) {\n                            ml_predict(fm, x) %>%\n                              mutate(Decile = ntile(desc(prediction), 10)) %>%\n                              group_by(Decile) %>%\n                              summarize(Gain = mean(Gain)) %>%\n                              select(Decile, Gain) %>%\n                              collect()}\n                        )\n})\n\n   user  system elapsed \n  0.560   0.021 532.135 \n\nCreate a summary dataset for plotting\n\n\nd_decile <- bind_rows(\n  as_tibble(model_deciles$d_trn) %>% mutate(partition = 'trn'),\n  as_tibble(model_deciles$d_tst) %>% mutate(partition = 'tst'))\n\nPlot average gains by predicted decile\n\n\nd_decile %>%\n  ggplot(aes(factor(Decile), Gain, fill = partition)) +\n  geom_bar(stat = 'identity', position = 'dodge') +\n  labs(title = 'Average gain by predicted decile', x = 'Decile', y = 'Minutes')\n\n\nprediction time ahead\n\n\nsystem.time({\npred_2008 <- ml_predict(fm, d_model_2008) %>%\n  group_by(Description) %>%\n  summarize(Gain = mean(Gain), prediction = mean(prediction), freq = n()) %>%\n  filter(freq > 10000) %>%\n  collect()\n})\n\n   user  system elapsed \n  0.240   0.004  35.131 \n\nPlot actual gains and predicted gains by airline carrier\n\n\nggplot(pred_2008, aes(Gain, prediction)) + \n  geom_point(alpha = 0.75, color = 'red', shape = 3) +\n  geom_abline(intercept = 0, slope = 1, alpha = 0.15, color = 'blue') +\n  geom_text(aes(label = substr(Description, 1, 20)), size = 3, alpha = 0.75, vjust = -1) +\n  labs(title='Average Gains Forecast', x = 'Actual', y = 'Predicted')\n\n\nClosing\nDisconnect from spark context\n\n\nspark_disconnect(sc)\n\n\n\n",
    "preview": "posts/2020-10-06-data-analysis-with-spraklyr/data-analysis-with-spraklyr_files/figure-html5/plot-1.png",
    "last_modified": "2020-10-10T02:07:00+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-10-07-functional-programming-with-r/",
    "title": "Functional Programming with R",
    "description": "`R` can be considered as a functional programming language as it focuses on the creation and manipulation of functions and has what's known as first class functions. Understanding the functional nature of `R` may help to improve clarity and avoid redundancy.",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2020-10-10",
    "categories": [],
    "contents": "\nR can be considered as a functional programming language as it focuses on the creation and manipulation of functions and has what’s known as first class functions.\nIn computer science, functional programming is a programming paradigm, a style of building the structure and elements of computer programs, that treats computation as the evaluation of mathematical functions and avoids state and mutable data.\nFunctional programming emphasizes functions that produce results that depend only on their inputs and not on the program state\nIn functional code, the output value of a function depends only on the arguments that are input to the function, so calling a function f() twice with the same value for an argument x will produce the same result f(x) both times. R is clearly a functional programming language.\nUnderstanding the functional nature of R may help to improve clarity and avoid redundancy.\nWe will examine:\nFirst Class Functions\nFunctions Closures\nFunctions Factories\nAnonymous Functions\nLists of Functions\nFunctionals\nFirst class functions\nFirst-class functions are a key component of functional programming style.\nA programming language is said to have first-class functions when the language supports:\npassing functions as arguments to other functions\ncreating anonymous functions\nreturning functions as the values from other functions\nstoring functions in data structures.\nand R has has first-class functions indeed.\nIn this example we pass function: identity() as argument to function lapply()\n\n\nlapply(0, identity)\n\n[[1]]\n[1] 0\n\nHere we make use of an anonymous function:\n\n\n(function(x) sd(x)/mean(x))(x = 1:5)\n\n[1] 0.5270463\n\nWe can easily define a function that return a function\n\n\nf <- function(){\n  function(x) sd(x)/mean(x)\n}\n\nFinaly we store functions within a list:\n\n\nfunction_list <- list(mean , sd)\n\nFunctions closures\nA function closure or closure is a function together with a referencing environment.\nAlmost all functions in R are closures as they remember the environment where they were created. Generally, but not always, the global environment:\n\n\nf <- function(x) 0\nenvironment(f)\n\n<environment: R_GlobalEnv>\n\nor the package environment\n\n\nenvironment(mean)\n\n<environment: namespace:base>\n\nFunctions that cannot be classified as closures, and therefore do not have a referencing environment, are know as primitives. These are internal R function calling the underlying C code. sum() and c() are good cases in point:\n\n\nenvironment(sum)\n\nNULL\n\nAs functions remember the environments where they were created, the following example does not return any error:\n\n\ny <- 1 \nf <- function(x){x+y}\nf(1)\n\n[1] 2\n\nThis is possible as f() is declared within the global environment and therefore f() remembers all objects bounded to that environment (the referencing environment), y included.\nWhen we call a function, a new environment is created to hold the function’s execution and, normally, that environment is destroyed when the function exits. But, if we define a function g() that returns a function f(), the environment where f() is created is the execution environment of g(), that is, the execution environment of g() is the referencing environment of f(). As a consequence, the execution environment of g() is not destroyed as g() exits but it persists as long as f() exists. Finally, as f() remembers all objects bounded to its referencing environment, f() remembers all objects bounded to the execution environment of g()\n\nWith this idea in mind, we can use the referencing environment of f(), that is the execution environment of g(), to hold any object and these objects will be available to f().\n\n\ng <- function(){\n  y <- 1\n  function(x) {x+y}\n}\nf1 <- g()\nf1(3)\n\n[1] 4\n\nMoreover, as f() is created within g() any argument passed to g() will be available to f() in its later executions.\n\n\ng <- function (y) {\n    function(x) x+y\n}\nf1 <- g(1)\nf1(3)\n\n[1] 4\n\nAs a proof of concept, we may temporaly modify function g() in order to print the execution environment of g()\n\n\ng_tmp <- function(y){\n  print(environment())\n  function(x) {x+y}\n}\n\nThan use g() to produce f()\n\n\nf1 <- g_tmp(1)\n\n<environment: 0x56068b663e00>\n\nand finaly ask R for the environment associated with f()\n\n\nenvironment(f1)\n\n<environment: 0x56068b663e00>\n\nAs we can see, the execution environment of g_tmp() corresponds to the environment associated to f().\nFinally,\n\n\nget(\"y\" , env = environment(f1))\n\n[1] 1\n\nshows where y is stored.\nNotice that each call to g() returns a function with its own referencing environment:\n\n\nf2 <- g(1)\nenvironment(f1)\n\n<environment: 0x56068b663e00>\n\nenvironment(f2)\n\n<environment: 0x56068ab2d1f0>\n\nThe referencing environments for f1() and f2() are different, despite that f1() and f2() are both returned by g().\nFunctions Factories\nIn practice, we can use closures to write specific functions that, in turn, can be used to generate new functions. This allows us to have a double layer of development: a first layer that is used to do all the complex work in common to all functions and a second layer that defines the details of each function.\nExample: A basic case in point\nWe can think of a simple function add(x,i) that add the value i to the value x. We could define this function as:\n\n\nadd <- function(x, i){\n  x+i\n}\n\nAlternatively, we may consider a set of functions, say f1(x), f2(x), ..., fi(x), ..., fn{x} that add 1,2,...,i,...,n to the x argument. Clearly, we do not want to define all these functions but we want to define a unique function f(i):\n\n\nf <- function(i){\n  function(x) {x+i}\n}\n\ncapable of generating all fi(x) functions:\n\n\nf1 <-  f(1)\nf1(3)\n\n[1] 4\n\nf2 <- f(2)\nf2(4)\n\n[1] 6\n\nIn this simple example, this approach shows no benefit and possibly increases the complexity of our codes but, for more structured cases, it is definitely worth.\nExample: MLE functions\nAs a more structured example, we may consider the development of a set of functions: lnorm(x), lweibull(x), ... that compute max likelihood estimates for those distributions given a vector of data x:\n\n\nnew_estimate <-  function(dist){\n  estimate <-  function(x, theta){   \n    neglik <-  function(theta = theta , x = x, log = T){\n      args <-  c(list(x), as.list(theta), as.list(log))\n      neglik <-  -sum(do.call(dist,  args))\n      neglik\n    }\n    optim(par = theta, fn = neglik , x = x)$par\n  }\nestimate\n}\n\nnew_estimate returns a second function: estimate() whose body depends on the argument dist passed to new_estimate().\nWithin estimate() we first define a third function neglik() and secondly, we minimize it within optim().\nThe returned function: estimate() can be used as a generator of maximum likelihood estimation functions for any distribution as long as its corresponding ddist() exists in R.\nOnce we have new_estimate(), we can use it to define any MLE estimation function as long as its density function is defined. That is, we can now write a llnorm() that computes log-normal maximum likelihood estimates as simply as:\n\n\nllnorm <- new_estimate(\"dlnorm\")\nx <- rlnorm(100, 7 , 1)\nllnorm(x, theta = c(mean(log(x)), sd(log(x))))\n\n[1] 6.972047 1.005196\n\nand similarly:\n\n\nlweibull <- new_estimate(\"dweibull\")\nw <- rweibull(100, 2 , 1)\nlweibull(w, theta = c(mean(w), sd(w)))\n\n[1] 1.868930 1.008663\n\nExample: moving statistics\nAs a further example of functions factories we may consider a function moving(f) that returns moving_f() where f() could be mean(), median() or any other statistical function as long it returns a single value.\nAs a first step we may consider a simple function g() that returns the value of f() for any backward window of length n starting at i:\n\n\ng <- function(i , x, n , f, ...) f(x[(i-n+1):i], ...)\ng(i = 5 , x = 1:10,n = 3  , f= mean) \n\n[1] 4\n\ng(i = 5 , x = 1:10,n = 3  , f= sd) \n\n[1] 1\n\nNote that g() takes, among its inputs, a second function f() and apply it to the window [(i-n+1):i] of x.\nAs a second step we define a function moving(f) that takes any function f() as an input and define function g() within its body.\n\n\nmoving <- function(f){\n  g <- function(i , x, n , f, ...) f(x[(i-n+1):i], ...)\n  h <- function(x, n, ...) {\n    N <- length(x)\n    vapply(n:N, g, x , n , f, FUN.VALUE = numeric(1), ...)\n  }\nreturn(h)  \n}\n\nFunction moving() returns function h() that, in turn can be used to generate any moving_f() functions:\nFunction vapply() within h() is a functional used as a for loop replacement that will be fully explored when discussing functionals.\n\n\nmoving_average <- moving(mean)  \nmoving_average(x = rpois(10, 10), n = 3)\n\n[1]  9.666667 10.333333 13.666667 12.000000 11.666667  8.000000\n[7]  9.666667  8.333333\n\nEventually, argument ’‘...’’ can be used to pass extra arguments to f().\n\n\nmoving_average(x = rpois(10, 10), n = 3, trim = .5)\n\n[1]  7 11 11 11  8  8 10 10\n\nIf necessary, function moving() ca be used in the form of anonymous function:\n\n\nmoving(sd)(rpois(10, 10), n = 5)\n\n[1] 3.563706 3.563706 3.114482 3.962323 4.159327 3.114482\n\nFinally:\n\n\nx <- 1:100\ny <- seq(along = x, from = 0 , to = 1)+rnorm(length(x), 0 , .1)\nplot(x, y)\nlines(x[10:length(x)], moving(mean)(y, 10), col = \"red\", lwd = 2)\nlines(x[10:length(x)], moving(median)(y, 10), col = \"green\", lwd = 2)\n\n\nFigure 1: Plot of moving average and median\n\n\n\nExample: Truncated density function\nDensity function in R are usually specified by the prefixes d followed by a standard suffix for each ditribution. dnorm(), dlnorm(), dweibull(), etc …\nTherefore, we use to write:\n\n\nx <- c(7,10,13)\ndlnorm(x , meanlog = 2, sdlog = 1)\n\n[1] 0.05690844 0.03810909 0.02616136\n\nin order to get density values at x from a lognormal distribution with parameters 2 and 1.\nIn case we need value from a truncated distribution, as far as we know, we need to load an extra package such as truncdist. The package itself works perfectly. In fact, assuming that a dlnorm() function exists, we can get density values from a left truncated lognormal distribution with parameters meanlog = 2 and sdlog = 1 by simply writing:\n\n\nrequire(truncdist)\ndtrunc(x, spec = \"lnorm\", a = 5)\n\n[1] 0.15962754 0.05237882 0.02127653\n\nwhere a = 5 represents the left threshold for truncation\nNevertheless, the above command require a change in our programming style.\nIn principle, we would like to be able to write:\n\n\ntdlnorm(x, meanlog = 2, sdlog = 1, L = 5)\n\nwhere L = 5 represents the left threshold for truncation\nso that we could have the same programming style, just with different parameters, for both truncated and not truncated distribution.\nWithin this frame, when tdlnorm() is called with L and U set to their default values it behaves as stats::dlnorm()\n\n\ntdlnorm(x, meanlog = 2, sdlog = 1)\n\nbut when called with different settings for L and U; such as:\ntdlnorm(x, meanlog = 2, sdlog = 1, L = 5, U = 20)\nit behaves as a lognormal density left truncated at L=5 and right truncated at U=20.\nThis goal could be achieved by writing a tdlnorm() as:\n\n\ntdlnorm <-  function (x, meanlog = 0, sdlog = 1,  L = 0,  H = Inf) \n {\n  \n  density <-  \n     stats::dlnorm(x, meanlog=meanlog, sdlog=sdlog)/\n        (\n        stats::plnorm(H, meanlog=meanlog, sdlog=sdlog)-  \n        stats::plnorm(L, meanlog=meanlog, sdlog=sdlog)  \n          )\n              \n   return(density)\n }\n\nThat returns the same results as function truncdist::dtrunc()\n\n\ntdlnorm(x, 1, 2, L= 5, H = 20)\n\n[1] 0.11523518 0.07297029 0.05109291\n\ndtrunc(x, spec = \"lnorm\", a = 5, b = 20, meanlog = 1, sdlog = 2)\n\n[1] 0.11523518 0.07297029 0.05109291\n\nAs this function clearly works, next step could be to write something similar for other distributions such as weibull, gumbel or gamma. We have to admit that all of this may become as quite time consuming.\nA different approach could be to define a different function, dtruncate(), taking the name of a density distribution as an argument and returning a second function that computes density values for the truncated distribution:\n\n\ndtruncate <-\n  function (dist, pkg = stats){ \n    \n    dist <- deparse(substitute(dist))\n    envir <- as.environment(paste(\"package\", as.character(substitute(pkg)), sep = \":\"))\n    \n    ddist=paste(\"d\", dist, sep = \"\") \n    pdist=paste(\"p\", dist, sep = \"\")\n        \n    #gets density function                    \n    ddist <-  get(ddist, mode = \"function\", envir = envir)\n    #gets argument of density function\n    dargs <- formals(ddist)\n   \n    #gets probability function                    \n    pdist <- get(pdist, mode = \"function\", envir = envir)\n    #gets argument of probability function\n    pargs <- formals(pdist)\n        \n    #Output function starts here\n    density <- function () \n    {\n      #check L U \n      if (L > U) stop(\"U must be greater than or equal to L\")\n      \n      #gets density arguments\n      call <- as.list(match.call())[-1]\n      \n      #all unique arguments belonging to density and ddist \n      dargs <- c(dargs[!is.element(names(dargs), names(call))], call[is.element(names(call), names(dargs))])\n      \n      #all unique arguments belonging to probability and pdist \n      pargs <- c(pargs[!is.element(names(pargs), names(call))], call[is.element(names(call), names(pargs))])\n      \n      #select x only where defined by L and U\n      dargs$x <- x[x > L & x <= U]\n      \n      #define arguments for pdist in L and U\n      pUargs <-  pLargs <- pargs \n      pUargs$q <- U\n      pLargs$q <- L\n      \n      #initialize output\n      density <- numeric(length(x))\n      \n      #standard method for computing density values for truncated distributions\n      density[x > L & x <= U] <-  do.call(\"ddist\", as.list(dargs)) / (do.call(\"pdist\", as.list(pUargs)) - do.call(\"pdist\", as.list(pLargs)))\n      \n      #returns density values for truncated distributions\n      return(density)\n      \n    }\n    \n    #add to density function formals L and U with values as passed with dtruncate\n    formals(density) <-  c(formals(ddist), eval(substitute(alist(L=-Inf, U=Inf))))\n    #return density function\n    return(density)\n  }\n\nwith:\nenvir: the environment plnorm() and dlnorm() belong to\nWe can now define a new tdlnorm() as:\n\n\ntdlnorm <- dtruncate(dist = lnorm)\n\nand use it as:\n\n\np <- ppoints(1000)\nx <- qlnorm(p, meanlog = 1, sdlog = 1)\nd <- tdlnorm(x, meanlog = 1, sdlog = 1)\ndt <- tdlnorm(x, meanlog = 1, sdlog = 1, L= 5, U = 10)\nplot(x, dt, type = \"n\", xlab = \"Quantile\", ylab = \"Density\")\npoints(x, dt, type = \"s\", col = \"red\", lwd = 2)\npoints(x, d, type = \"s\", col = \"darkblue\", lwd = 2)\ntitle(\"Truncated and not-truncated log-normal\")\ngrid()\n\n\nclearly, tdlnorm() returns the same results as truncdist::dtrunc():\n\n\ndtrunc(x = 5:8, spec = \"lnorm\", a = 5, b = 10, meanlog = 1, sdlog = 1)\n\n[1] 0.3791833 0.2780953 0.2084880 0.1593537\n\ntdlnorm(x = 5:8, meanlog = 1, sdlog = 1, L = 5, U = 10)\n\n[1] 0.0000000 0.2780953 0.2084880 0.1593537\n\nMoreover, our newly created tdlnorm() function takes as argument meanlog and sdlog, as well as lower.tail = TRUE, log.p = FALSE, as stats::plnorm() does, despite these arguments were not mentioned when calling dtruncate().\nNow that we have dtruncate(), the same exercise can be replicate, at no extra programming effort, to any density function:\n\n\ndweibull <-  dtruncate(dist = weibull)\ndgpd <- dtruncate(gpd, pkg = evd)\n\nFunctions with memory\nWhen talking about clousures, we used the referencing environment of f() to hold any value passed by g(). Similarly, we can use the same environment to keep a state across multiple executions of f().\nExample: Track how many times a function is called\nWe may consider a function that simply returns the current date but tracks how many times it has ben called:\n\n\ng <- function(){\n i <- 0\n f <- function(){\n    i <<- i+1\n    cat(\"this function has been called \", i, \" times\", \"\\n\")\n    date()  \n}}\n\nf <- g()\n#first call\nf()\n\nthis function has been called  1  times \n\n[1] \"Sat Oct 10 01:15:39 2020\"\n\n#second call\nf() \n\nthis function has been called  2  times \n\n[1] \"Sat Oct 10 01:15:39 2020\"\n\n#third call\nf()\n\nthis function has been called  3  times \n\n[1] \"Sat Oct 10 01:15:39 2020\"\n\nNote that, we used the <<- operator that assigns in the parent environment. This is equivalent to:\n\n\nassign(\"i\", i+1, envir = parent.env(environment())):\n\nExample: Avoid re-calculate previous results\nWe can use the referencing environment of a function to keep previous returned values of the same function. By using this idea, we could try to avoid re-calculating previously computed values.\nSupose we want a function that takes n as argument and returns all primes less or equal to n. This function already exists within library pracma:\n\n\nlibrary(pracma)\nprimes(n = 9)\n\n[1] 2 3 5 7\n\nIn order to keep previous results we can define a function makefprime() that, when called, returns a second function with an environment .env attached:\n\n\nmakefprime = function () {\n  .env = new.env()\n  f = function(n) {\n    symbol = paste(\"p\", n, sep = \".\")\n    if (exists(symbol, envir = .env)){\n      prime = get(symbol, envir = .env)\n    } \n    else {prime = primes(n = n)\n      assign(symbol , prime, envir = .env)\n    }\n    prime\n   }  \nf\n}\n\nWe can now create a function named for instance fprimes() by calling function makefprime() which returns identical results when compared with primes().\n\n\nfprimes = makefprime()\nfprimes(10)\n\n[1] 2 3 5 7\n\nNow suppose we need to compute prime numbers several time within a working session or a for loop. When n is large, this computation may require a substancial ammount of time.\n\n\nsystem.time({p1 = fprimes(n = 10^7)})\n\n   user  system elapsed \n  0.338   0.041   0.383 \n\nNevertheless, because of the way we defined fprimes(), second time this function is called with n = 10^7 computing time is practicaly zero as the function reuse previously computed results as stored in environment .env.\n\n\nsystem.time({p2 = fprimes(n = 10^7)})\n\n   user  system elapsed \n      0       0       0 \n\n\nExample: Add to an existing plot\nAs a last example, we may want to have a function that add to an existing plot any time a new observation becomes available, using the same mechanism, we can define a new_plot() function that instances a new plot the first time it is called:\n\n\nnew_plot = function(){\n  xx = NULL\n  yy = NULL\n  function(x, y, ...) {\n  xx <<- c(xx, x)\n  yy <<- c(yy, y)\n  plot(xx, yy, ...)\n}}\n\nthis_plot <- new_plot()\n\nand add to the same plot at each next call:\n\n\nthis_plot (1:4, c(2, 3, 1, 5), type = \"b\")\n\n\nFigure 2: first call\n\n\n\n\n\nthis_plot(5, 3, type = \"b\")\n\n\nFigure 3: second call\n\n\n\n\n\nthis_plot(6, 3, type = \"b\", col = \"red\")\n\n\nFigure 4: third call\n\n\n\n\nAnonymous functions\nIn R, we usually assign functions to variable names. Nevertheless, functions can exists without been assigned to symbol. Functions that don’t have a name are called anonymous functions.\nWe can call anonymous functions directly, as we do with named functions, but the code is a little unusual as we have to use brackets both to include the whole function definition and to pass arguments to the function:\n\n\n(function(x) x + 3)(10)\n\n[1] 13\n\nNote that this is exactly the same as:\n\n\nf <- function(x) x + 3\nf(10)\n\n[1] 13\n\nWe use anonymous functions when it’s not worth the effort of assigning functions to a name. We could plot a function s(x) by:\n\n\ns <- function(x) sin(x)/sqrt(x)\nintegrate(s,  0, 4)\n\n1.609553 with absolute error < 4.5e-11\n\nor alternatively by:\n\n\nintegrate(function(x) sin(x)/sqrt(x),  0, 4)\n\n1.609553 with absolute error < 4.5e-11\n\nin this case function(x) sin(x)/sqrt(x) is an example of anonymous function.\nFinally, anonymous functions are, by all rights, normal R functions as they have formals(), a body(), and a parent environment():\n\n\nformals(function(x) x+1)\n\n$x\n\nbody(function(x) x+1)\n\nx + 1\n\nenvironment(function(x) x+1)\n\n<environment: R_GlobalEnv>\n\nLists of functions\nFunctions, as any type of R object, can be stored in a list.\n\n\nfun_list <- list(m = mean , s = sd)\n\nThis makes it easier to work with groups of related functions.\nFunctions defined within a list are still accessible at least in three different ways:\nusing function with()\n\n\nwith (fun_list, m(x = 1:10))\n\n[1] 5.5\n\nby using the $ operator\n\n\nfun_list$m( x = 1:10)\n\n[1] 5.5\n\nby attaching the list:\n\n\nattach(fun_list)\nm( x = 1:10)\n\n[1] 5.5\n\ndetach(fun_list)\n\nLists of functions can be most useful when we want to apply all functions of the list to the same set of data.\nWe can achieve this goal in two logical steps.\nWe first define a function\n\n\nfun <- function(f, ...){f(...)}\n\nthat takes a function f() as argument along with any other arguments ’‘...’’ and returns f(...). In practice:\n\n\nfun(mean, x = 1:10, na.rm = TRUE)\n\n[1] 5.5\n\nSecondly, we apply function fun() to the list of functions. Arguments required by the functions stored in the list are passed by the ’‘...’’ argument:\n\n\nlapply(fun_list, fun, x = 1:10)\n\n$m\n[1] 5.5\n\n$s\n[1] 3.02765\n\nUnder almost all circumstances, equivalent results can be achieved by using function do.call() within a call to lapply():\n\n\nlapply(fun_list, do.call, list(x = 1:10, na.rm = T))\n\n$m\n[1] 5.5\n\n$s\n[1] 3.02765\n\nthe only difference being that arguments to functions within the list must be enclosed in a list too.\n\nExample: Multiple Anderson-Darling tests\nAs a simple example we may want to compare the results of four Anderson-Darling type tests from the truncgof package applied to the same data.\nWe can define a list that holds these four functions and store it in the global environment:\n\n\nrequire(truncgof, quietly = TRUE)\nnor_test <- list(ad2.test = ad2.test, ad2up.test = ad2up.test, ad.test = ad.test, \n    adup.test = adup.test)\n\nand, afterword, apply function fun() to each element of this list:\n\n\nx <- rnorm(100, 10, 1)\nm <-  mean(x)\ns <- sd(x)\nlapply(nor_test, fun, x , distn = \"pnorm\", list(mean = m, sd = s), sim = 100)\n\n$ad2.test\n\n    Quadratic Class Anderson-Darling Test\n\ndata:  x\nAD2 = 0.77067, p-value = 0.03\n\ntreshold = -Inf, simulations: 100\n\n\n$ad2up.test\n\n    Quadratic Class Anderson-Darling Upper Tail Test\n\ndata:  x\nAD2up = 2.7084, p-value = 0.61\n\ntreshold = -Inf, simulations: 100\n\n\n$ad.test\n\n    Supremum Class Anderson-Darling Test\n\ndata:  x\nAD = 1.6421, p-value = 0.7\nalternative hypothesis: two.sided\n\ntreshold = -Inf, simulations: 100\n\n\n$adup.test\n\n    Anderson-Darling Upper Tail Test\n\ndata:  x\nADup = 10, p-value = 0.51\nalternative hypothesis: two.sided\n\ntreshold = -Inf, simulations: 100\n\nExample: Summary statistics\nWe may want to define a function that returns some specific statistics for a given set of variables in the form of a data.frame.\n\n\nthis_summary <- as.data.frame(rbind(vapply(trees, mean, FUN.VALUE = numeric(1)), \n    vapply(trees, sd, FUN.VALUE = numeric(1)), vapply(trees, function(x, \n        ...) {\n        diff(range(x))\n    }, FUN.VALUE = numeric(1))))\n\nrow.names(this_summary) <- c(\"mean\", \"sd\", \"range\")\nthis_summary\n\n          Girth    Height   Volume\nmean  13.248387 76.000000 30.17097\nsd     3.138139  6.371813 16.43785\nrange 12.300000 24.000000 66.80000\n\nWe may achieve the same result by writing a more general function that will work with any kind of statistics as long as they return a single value:\n\n\nmy_summary <- function(x, flist) {\n    f <- function(f, ...) f(...)\n    g <- function(x, flist) {\n        vapply(flist, f, x, FUN.VALUE = numeric(1))\n    }\n    df <- as.data.frame(lapply(x, g, flist))\n    row.names(df) <- names(flist)\n    df\n}\n\nmy_summary(cars, flist = list(mean = mean, stdev = sd, cv = function(x, \n    ...) {\n    sd(x, ...)/mean(x, ...)\n}))\n\n           speed       dist\nmean  15.4000000 42.9800000\nstdev  5.2876444 25.7693775\ncv     0.3433535  0.5995667\n\nfapply\nWorking with this mind set we may even define a function fapply() that applies all functions of a list to the same set of arguments\n\n\nfapply <- function(X, FUN, ...){\n  lapply(FUN, function(f, ...){f(...)}, X, ...)\n}\n\nand use it as:\n\n\nbasic_stat <- list(mean = mean, median = median, sd = sd)\nfapply(1:10, basic_stat)\n\n$mean\n[1] 5.5\n\n$median\n[1] 5.5\n\n$sd\n[1] 3.02765\n\n\n\n",
    "preview": "posts/2020-10-07-functional-programming-with-r/functional-programming-with-r_files/figure-html5/closures-023-1.png",
    "last_modified": "2020-10-10T01:15:42+02:00",
    "input_file": {},
    "preview_width": 1344,
    "preview_height": 768
  },
  {
    "path": "posts/2020-09-24-install-shinyproxy/",
    "title": "Install ShinyProxy",
    "description": "How to install shiny proxy in Ubuntu",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2020-09-24",
    "categories": [],
    "contents": "\nYou can have ShinyProxy container up and running on your Ubuntu machine bu following teh next four steps:\nGet shyproxy Dockerfile\nWrite your own application.yml configuration file\nbuild the container\nRun the container\nDockerfile\nYou can download the Dockerfile for shinyServer at https://github.com/og-analytics.\nCloning this repository provides several files required to follow all the tutorials displayed at the page\nNevertheless, the only file you need to accomplish step (1) is text file named Dockerfile with the following content:\n\n\nFROM openjdk:8-jre\n\nRUN mkdir -p /opt/shinyproxy/\nRUN wget https://www.shinyproxy.io/downloads/shinyproxy-2.3.1.jar -O /opt/shinyproxy/shinyproxy.jar\nCOPY application.yml /opt/shinyproxy/application.yml\n\nWORKDIR /opt/shinyproxy/\nCMD [\"java\", \"-jar\", \"/opt/shinyproxy/shinyproxy.jar\"]\n\nThis dockerfile contains the instructions for performing the next four tasks\ngets the basic jre container from dockerhub\ngets shinyproxy application and copy it inside the docker\ncopies application.yml inside the docker\nstarts ShinyProxy inside the container when the container starts\nTasks (c) requires application.yml that, in turn, require to be there and properly configured when building the container. This files basically tells the container how to interact with the surrounding environment including how to interact with any shiny application.\napplication.yml\n\n\n",
    "preview": {},
    "last_modified": "2020-09-24T01:22:50+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-15-install-docker-engine/",
    "title": "Docker Installation",
    "description": "How to install Docker system on Ubuntu",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2020-09-23",
    "categories": [],
    "contents": "\n\nPrerequisites\nInstall Java\n\n\nsudo apt install default-jre\n\nCheck your version of Java is Java 8\n\n\njava -version\n\nyou should see something like:\n\n\nopenjdk version \"11.0.8\" 2020-07-14\nOpenJDK Runtime Environment (build 11.0.8+10-post-Ubuntu-0ubuntu120.04)\nOpenJDK 64-Bit Server VM (build 11.0.8+10-post-Ubuntu-0ubuntu120.04, mixed mode, sharing)\n\nUpdate your system\n\n\nsudo apt-get update\n\nInstall dependencies\n\n\nsudo apt-get install \\\n    apt-transport-https \\\n    ca-certificates \\\n    curl \\\n    gnupg-agent \\\n    software-properties-common\n\nAdd gpk key\n\n\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n\nVerify it is installed\n\n\nsudo apt-key fingerprint 0EBFCD88\n\nand it should return\n\n\npub   rsa4096 2017-02-22 [SCEA]\n      9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88\nuid           [ unknown] Docker Release (CE deb) <docker@docker.com>\nsub   rsa4096 2017-02-22 [S]\n\nAdd docker repository\n\n\nsudo add-apt-repository \\\n   \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n   $(lsb_release -cs) \\\n   stable\"\n\nInstall docker\n\n\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io\n\nVerify installation\nYou can now test your docker engine with the basic hello-world container\n\n\nsudo docker run hello-world\n\nYour system should take care of downloading the docker image from Docker Hub, build it and run it. Output should look like:\n\n\nUnable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\n0e03bdcc26d7: Pull complete \nDigest: sha256:4cf9c47f86df71d48364001ede3a4fcd85ae80ce02ebad74156906caff5378bc\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n\nYou can check the status of the docker service by\n\n\nsudo service docker status\n\nDocker version is returned by:\n\n\nsudo docker version\n\n\n\n",
    "preview": {},
    "last_modified": "2020-09-23T10:28:41+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-22-install-portainer/",
    "title": "Install Portainer",
    "description": "How to install Portainer on Ubuntu",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2020-09-23",
    "categories": [],
    "contents": "\nWhat is Portainer\nPortainer is a lightweight management user interface that allows you to easily manage your Docker environments through a web interface.\nPortainer provides multiple options to interface with images and containers. Managing images and containers may become easier with a good user interface for Docker.\nThis article briefly describes how to install Portainer on you Ubuntu system assuming that your docker engine is already up and running\nA more extensive range of information about Portainer can be found at https://www.portainer.io/.\nYou can accomplish Portainer installation by downloading Portainer image from the DockerHub using the docker pull command\n\n\nsudo docker pull portainer/portainer\n\nOnce the image is downloaded you can start Portainer with\n\n\nsudo docker run -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock --name portainer portainer/portainer\n\nAssuming everything worked correctly, when pointing at: ip-addess:9000, after setting up password for admin user, you should see something like:\n\n\n\n\nIn case of trouble, just use the old restart trick\n\n\nsudo docker container restart portainer\n\n\n\n",
    "preview": "posts/2020-09-22-install-portainer/distill-preview.png",
    "last_modified": "2020-09-23T00:19:12+02:00",
    "input_file": {},
    "preview_width": 1871,
    "preview_height": 439
  },
  {
    "path": "posts/2020-09-19-shiny-app-in-a-container/",
    "title": "How to dockerise a Shiny app",
    "description": "How to port a shiny app into a container",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2020-09-20",
    "categories": [],
    "contents": "\n\nPrerequisites\nIn order to build a container with your shiny app inside you need three files:\napp.R containing your working shiny app\nDockerfile\nRprofile.site\nStarting from your working directory proj, teh file hierarchy must be:\n\n-- proj \n   -- Dockerfile\n   -- Rprofile.site\n   -- iris\n      -- app.R\napp.R\nYour app.R contains your shiny app. As a first example you may consider the iris example from https://shiny.rstudio.com/gallery/kmeans-example.html. The iris example is also available here. Store app.R inside the application directory say iris.\nDockerfile\nYour docker file contains the following instructions:\n\n\n# where to download the base R docker image from\nFROM rocker/r-base\n\n# system libraries commonly required by R packages\nRUN apt-get update && apt-get install -y \\\n    sudo \\\n    pandoc \\\n    pandoc-citeproc \\\n    libcurl4-gnutls-dev \\\n    libcairo2-dev \\\n    libxt-dev \\\n    libssl-dev \\\n    libssh2-1-dev\n\n\n# Install required packages\nRUN R -e \"install.packages(c('shiny', 'rmarkdown'), repos='https://cloud.r-project.org/')\"\n\n\n# copy the app to the image\nRUN mkdir /root/iris\nCOPY iris /root/iris\n\n\nCOPY Rprofile.site /usr/lib/R/etc/\n\nEXPOSE 3333\n\nCMD [\"R\", \"-e\", \"shiny::runApp('/root/iris')\"]\n\n\nRprofile.site\nThe Rprofile.site file states that:\n\n\nlocal({\n   options(shiny.port = 3333, shiny.host = \"0.0.0.0\")\n})\n\nBuild the container\nBuild docker image with\n\n\nsudo docker build   --tag iris .\n\nTest by\nAssuming that everything worked out correctly, if you issue:\n\n\nsudo docker run -it --rm -p 3333:3333 iris \n\nyou should see the iris application at 0.0.0.0:3333\n\n\n",
    "preview": {},
    "last_modified": "2020-09-20T11:51:52+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-09-20-how-to-move-docker-data-direcory/",
    "title": "Docker data direcory",
    "description": "How to move docker data direcory to a different location in ubuntu.",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "andreaspano.github.io"
      }
    ],
    "date": "2020-09-20",
    "categories": [],
    "contents": "\nThe default data directory used by docker system for storing images is /var/lib/docker. You may want to move this directory to another location on your system.\nThis goal can be achieved by following the next steps:\nStop the docker daemon\n\n\nsudo service docker stop`\n\nAdd a configuration file named daemon.json under the directory /etc/docker. The file should have this content:\n\n\n{ \n   \"graph\": \"/path/to/your/docker\" \n}\n\nCopy the current data directory to the new one\n\n\nsudo rsync -aP /var/lib/docker/ /path/to/your/docker\n\nRename the old docker directory\n\n\nsudo mv /var/lib/docker /var/lib/docker.old\n\nRestart the docker daemon\n\n\nsudo service docker start\n\nTest\nCreate a new doocker and check that a new image appears in /path/to/your/docker\nCleanup\nWhen you are sure that the new directory is being used correctly by docker daemon you can delete the old data directory.\n\n\nsudo rm /var/lib/docker\n\ninsights\nPlease check (Destrero 2020) for more detailed tutorial on this topic\n\n\nDestrero, Augusto. 2020. “How to Move Docker Data Directory to Another Location on Ubuntu.” https://www.guguweb.com/2019/02/07/how-to-move-docker-data-directory-to-another-location-on-ubuntu/.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2020-09-20T20:17:07+02:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to andreaspano blog ",
    "description": "Welcome to my blog; \nthe place where I am trying to write what I learn about",
    "author": [
      {
        "name": "Andrea Spano",
        "url": "https://andreaspano.github.io/"
      }
    ],
    "date": "2020-09-01",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": "posts/welcome/images/welcome.jpg",
    "last_modified": "2020-09-23T09:34:10+02:00",
    "input_file": {}
  }
]
